# Reply with response
* [Application code](#application-code)
* [Register service](#register-service)
* [Serve request](#serve-request)                                
  * [Prepare for stream](#prepare-for-stream)
  * [Serve stream](#serve-stream) 
  * [Handle request](#handle-request)

gRPC over HTTP 2 use HTTP 2 frames. But how to do that exactly? let's explain the detail of implementation of server side response. [gRPC over HTTP2](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md) is a good start point to explain the design of gRPC over HTTP 2. In brief, the gRPC call response is transformed into three parts:

```
Response → (Response-Headers *Length-Prefixed-Message Trailers) / Trailers-Only
```

* A header frame (***Response-Headers***),
* Zero or more data frame (***Length-Prefixed-Message***),
* The final part is ***Trailers***. A special kind of header frame which can be sent after the body. These headers allow for metadata that can’t be calculated up front. In special case, Trailers can be send alone. 

Please refer to the [Send Request](request.md) to get more information about the request. After all we need to know the request to give the correct reply.

## Application code

Here is the gRPC server side application code snippet. It uses ```net.Listen("tcp", port)``` to bind the server side listening port. Then it create a gRPC server with ```grpc.NewServer() ``` and register the implementation of ```"helloworld.GreeterServer"``` service on the gRPC server. At last, it uses ```s.Serve(lis)```to serve the the listening port.

Plase note that the ```server.SayHello()``` will be the destination of gRPC request. Which means it will not serve the client side request directly. Let's continue our analysis from ```pb.RegisterGreeterServer()```. Which prepares the necessary configuration for the gRPC call. 

It's easy, right? With the help from protocol buffer encapsulation, the ```server``` implementation is easy. It just implement the ```SayHello()``` method defined by IDL. 

```go
const (                                
    port = ":50051"                                
)                                
                                
// server is used to implement helloworld.GreeterServer.                                
type server struct {                                
    pb.UnimplementedGreeterServer                                
}                                
                                
// SayHello implements helloworld.GreeterServer                                
func (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {                                
    log.Printf("Received: %v", in.GetName())                                
    return &pb.HelloReply{Message: "Hello " + in.GetName()}, nil                                
}                                
                                
func main() {                                
    lis, err := net.Listen("tcp", port)                                
    if err != nil {                                
        log.Fatalf("failed to listen: %v", err)                                
    }                                
    s := grpc.NewServer()                                
    pb.RegisterGreeterServer(s, &server{})                                
    if err := s.Serve(lis); err != nil {                                
        log.Fatalf("failed to serve: %v", err)                                
    }                                
}                                
```
## Register service
Let's move on to see what happens under the hood. The following code is generated by gRPC plugin. ```grpc.ServiceDesc``` is a data structure to store the service related configuration. 

```_Greeter_SayHello_Handler``` is the so called ```methodHandler```. ```methodHandler``` will be called  when the server got the correct gRPC request instead of the ```server.SayHello()``` method you just provided. Why? Because protocol buffer message need to be decoded and lots of features provided by gRPC need to get a chance to run.

```_Greeter_SayHello_Handler``` use ```dec(in)``` to decode the incoming message and construct the HelloRequest object. If any interceptor (chain) exist, it wrap the ```GreeterServer.SayHello()``` with ```UnaryHandler``` and use the ```UnaryHandler``` as parameter to call the interceptor. 

The ```srv.(GreeterServer).SayHello(ctx, in)``` and ```interceptor(ctx, in, info, handler)``` share the same return type. With this design, if there exists any interceptor, it will got a chance to run. See [Interceptor](interceptor.md) for more detail.

```go
func RegisterGreeterServer(s grpc.ServiceRegistrar, srv GreeterServer) {                                
    s.RegisterService(&_Greeter_serviceDesc, srv)                                
}                                
                                
func _Greeter_SayHello_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error)       {                                                                
    in := new(HelloRequest)                                
    if err := dec(in); err != nil {                                
        return nil, err                                
    }                                
    if interceptor == nil {                                
        return srv.(GreeterServer).SayHello(ctx, in)                                
    }                                
    info := &grpc.UnaryServerInfo{                                
        Server:     srv,                                
        FullMethod: "/helloworld.Greeter/SayHello",                                
    }                                
    handler := func(ctx context.Context, req interface{}) (interface{}, error) {                                
        return srv.(GreeterServer).SayHello(ctx, req.(*HelloRequest))                                
    }                                
    return interceptor(ctx, in, info, handler)                                
}                                
                                
var _Greeter_serviceDesc = grpc.ServiceDesc{                                
    ServiceName: "helloworld.Greeter",                                
    HandlerType: (*GreeterServer)(nil),                                
    Methods: []grpc.MethodDesc{                                
        {                                
            MethodName: "SayHello",                                
            Handler:    _Greeter_SayHello_Handler,                                
        },                                
    },                                
    Streams:  []grpc.StreamDesc{},                                
    Metadata: "examples/helloworld/helloworld/helloworld.proto",                                
}  
...
type methodHandler func(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor UnaryServerInterceptor) (interface{}, error)

// UnaryHandler defines the handler invoked by UnaryServerInterceptor to complete the normal
// execution of a unary RPC. If a UnaryHandler returns an error, it should be produced by the
// status package, or else gRPC will use codes.Unknown as the status code and err.Error() as
// the status message of the RPC.
type UnaryHandler func(ctx context.Context, req interface{}) (interface{}, error)
...
```
```RegisterService()``` first make sure the ```ss``` implement the ```*GreeterServer``` interface. which is defined by the IDL and generated by gRPC. 

```s.register()``` register the service in the gRPC server. it also convert the ```ServiceDesc``` into ```serviceInfo```. 

In gRPC server, the service is mainly registered by the service name, method name and service implementation. When the client send a gRPC request, the client need to provide both the service name and method name in request. see [Send Request](request.md) for more detail.

In this case:
* service name is ```"helloworld.Greeter"```, method name is ```"SayHello"```.
* in ```Server``` struct, the ```services``` is a map, its key is the service name, the value is the ```serviceInfo```.

```go
// RegisterService registers a service and its implementation to the gRPC
// server. It is called from the IDL generated code. This must be called before
// invoking Serve. If ss is non-nil (for legacy code), its type is checked to
// ensure it implements sd.HandlerType.
func (s *Server) RegisterService(sd *ServiceDesc, ss interface{}) {
    if ss != nil {                                      
        ht := reflect.TypeOf(sd.HandlerType).Elem()                                                                    
        st := reflect.TypeOf(ss)           
        if !st.Implements(ht) {                                                                                                 
            logger.Fatalf("grpc: Server.RegisterService found the handler of type %v that does not satisfy %v", st, ht)
        }                     
    }
    s.register(sd, ss) 
}                                                           

func (s *Server) register(sd *ServiceDesc, ss interface{}) {
    s.mu.Lock()                                                                                                          
    defer s.mu.Unlock()                                                                                                     
    s.printf("RegisterService(%q)", sd.ServiceName)
    if s.serve {
        logger.Fatalf("grpc: Server.RegisterService after Server.Serve for %q", sd.ServiceName)
    }
    if _, ok := s.services[sd.ServiceName]; ok {
        logger.Fatalf("grpc: Server.RegisterService found duplicate service registration for %q", sd.ServiceName)
    }
    info := &serviceInfo{
        serviceImpl: ss,
        methods:     make(map[string]*MethodDesc),
        streams:     make(map[string]*StreamDesc),
        mdata:       sd.Metadata,
    }
    for i := range sd.Methods {
        d := &sd.Methods[i]
        info.methods[d.MethodName] = d
    }
    for i := range sd.Streams {
        d := &sd.Streams[i]
        info.streams[d.StreamName] = d
    }
    s.services[sd.ServiceName] = info
}
...
type Server struct {
    opts serverOptions                                                                         
     
    mu       sync.Mutex // guards following     
    lis      map[net.Listener]bool                                                                               
    conns    map[transport.ServerTransport]bool
    serve    bool        
    drain    bool       
    cv       *sync.Cond              // signaled when connections close for GracefulStop
    services map[string]*serviceInfo // service name -> service info
    events   trace.EventLog      
     
    quit               *grpcsync.Event
    done               *grpcsync.Event
    channelzRemoveOnce sync.Once      
    serveWG            sync.WaitGroup // counts active Serve goroutines for GracefulStop
                               
    channelzID int64 // channelz unique identification number
    czData     *channelzData          
     
    serverWorkerChannels []chan *serverWorkerData
}
```

## Serve request

The following diagram is the serve request sequence. It focus on the reply the response: mainly ***Response-Headers***, ***Length-Prefixed-Message*** and ***Trailers***.

![images.004.png](images/images.004.png)

Now everything is ready. Let's serve the gRPC request. ```Serve(``` need to be called from your application code. It will be the main goroutine to serve request. 

Its job is:
* wait and accep the incoming connection and 
* start a new goroutine to process the incoming connection. 

The following connection request will not be blocked because of the anonymous goroutine. Here I fold some unrelated code to make it easy to understand our topic.

```go
// Serve accepts incoming connections on the listener lis, creating a new
// ServerTransport and service goroutine for each. The service goroutines
// read gRPC requests and then call the registered handlers to reply to them.
// Serve returns when lis.Accept fails with fatal errors.  lis will be closed when
// this method returns.
// Serve will return a non-nil error unless Stop or GracefulStop is called.
func (s *Server) Serve(lis net.Listener) error {
...
    for {
        rawConn, err := lis.Accept()
        if err != nil {
+-- 31 lines: if ne, ok := err.(interface {····················································································································
        }                       
        tempDelay = 0                 
        // Start a new goroutine to deal with rawConn so we don't stall this Accept
        // loop goroutine.                          
        //              
        // Make sure we account for the goroutine so GracefulStop doesn't nil out
        // s.conns before this conn can be added.
        s.serveWG.Add(1)                                    
        go func() {                
            s.handleRawConn(rawConn)
            s.serveWG.Done()
        }()                                                                 
    }                        
}                                                
```

### Prepare for stream
```handleRawConn()``` call ```s.useTransportAuthenticator``` first. (I still need some time to understand this part.)

Then it call ```s.newHTTP2Transport()```, this function finish the following job.
* send the server side SETTING frame to the client.
* adjust the connection flow control window if needed.
* create the controlBuffer ```t.controlBuf```. For now, just remember controlBuffer is a way to pass information to loopy. See [controlBuffer and loopy](control.md) for detail. 
* check and validate the (HTTP 2) connection preface magic string.
* receive and process client SETTING frame
* create the ```loopyWriter``` and run it in a new goroutine. For now, just remember ```loopyWriter``` works closely with ```t.controlBuf``` to process HTTP 2 frame. We will talk about it in separate chapter.
* launch a new ```t.keepalive()``` goroutine to manage the connection state (e.g. close idle connection, keep alive active connection, etc. )

Those who are familar with HTTP 2 protocol will find the above work is necessary before accepting the client request. We will NOT show ```s.newHTTP2Transport()``` related code. Showing that code will complicate and disturb our focus. ***TODO consider a new chapter?*** 

In short , the ```s.newHTTP2Transport()``` prepare for the next step: process streams.

The last part is processing the stream. ```s.serveStreams()``` will process the streams in a separate goroutine. 
```go
// handleRawConn forks a goroutine to handle a just-accepted connection that
// has not had any I/O performed on it yet.
func (s *Server) handleRawConn(rawConn net.Conn) {
    if s.quit.HasFired() {
        rawConn.Close()
        return
    }
    rawConn.SetDeadline(time.Now().Add(s.opts.connectionTimeout))
    conn, authInfo, err := s.useTransportAuthenticator(rawConn)
    if err != nil {
        // ErrConnDispatched means that the connection was dispatched away from
        // gRPC; those connections should be left open.
        if err != credentials.ErrConnDispatched {
            s.mu.Lock()
            s.errorf("ServerHandshake(%q) failed: %v", rawConn.RemoteAddr(), err)
            s.mu.Unlock()
            channelz.Warningf(logger, s.channelzID, "grpc: Server.Serve failed to complete security handshake from %q: %v", rawConn.RemoteAddr(), err)
            rawConn.Close()
        }
        rawConn.SetDeadline(time.Time{})
        return
    }
 
    // Finish handshaking (HTTP2)
    st := s.newHTTP2Transport(conn, authInfo)
    if st == nil {
        return
    }
 
    rawConn.SetDeadline(time.Time{})
    if !s.addConn(st) {
        return
    }
    go func() {
        s.serveStreams(st)
        s.removeConn(st)
    }()
}
```
### Serve stream

```serveStreams()``` call the ```st.HandleStreams()``` and provide a anonymous function as parapmeter, which is a wrapper for ```s.handleStream()```. ```serveStreams()``` run in its goroutine and can handle different streams. Inside the wrapper, ```s.handleStream()```` also run in a separate goroutine. please note ```st.HandleStreams()``` and ```s.handleStream()``` are different function with similar function name. Although their function signagure is different. 

```go
func (s *Server) serveStreams(st transport.ServerTransport) {
    defer st.Close()
    var wg sync.WaitGroup                                                                                                                                        
                                                                                                                                                  
    var roundRobinCounter uint32                                                                                                                        
    st.HandleStreams(func(stream *transport.Stream) {                                                                                              
        wg.Add(1)                                                                                                          
        if s.opts.numServerWorkers > 0 {                                                                                   
            data := &serverWorkerData{st: st, wg: &wg, stream: stream}                                                     
            select {                                                                                                       
            case s.serverWorkerChannels[atomic.AddUint32(&roundRobinCounter, 1)%s.opts.numServerWorkers] <- data:          
            default:                                                                                                       
                // If all stream workers are busy, fallback to the default code path.                                      
                go func() {                                                                                                
                    s.handleStream(st, stream, s.traceInfo(st, stream))                                                    
                    wg.Done()                                                                                                                        
                }()                                                                                                        
            }                                                                                                              
        } else {                                                                                                                                       
            go func() {                                                                                                    
                defer wg.Done()                                                                                                         
                s.handleStream(st, stream, s.traceInfo(st, stream))                                                                               
            }()                                                                                                                                                  
        }                                                                                                                                                
    }, func(ctx context.Context, method string) context.Context {                                                                                               
        if !EnableTracing {                                                                                                                           
            return ctx                                                                                                                                
        }
        tr := trace.New("grpc.Recv."+methodFamily(method), method)
        return trace.NewContext(ctx, tr)
    })
    wg.Wait()
}
```

```HandleStreams()``` read a frame with ```ReadFrame()``` and process it according to the different frame type.  

Actually ```ReadFrame()``` can read all kinds of frame. It perform the following work: 
* read frame header 
* read frame payload data 
* parse the paylod data to build different frame
* check frame order to find invalid frame, and mostly check whether HEADERS and CONTINUATION frames are contiguous.
* read 0 or more CONTINUATION frames and merge them into MetaHeadersFrame.

if ```ReadFrame()``` return MetaHeadersFrame type, then ***Request-Headers*** is received by the server.

After ```ReadFrame()``` ```HandleStreams()``` will process the frame according to the frame type. Most frames will be processed here. Such as PingFrame, WindowUpdateFrame, GoAwayFrame, SettingsFrame, even RSTStreamFrame in some case. 

```MetaHeadersFrame``` is a special Frame. It represent the start point of gRPC method call. There is no MetaHeadersFrame in HTTP 2 protocol. For gRPC method call, process one HEADER frame plus zero or more CONTINUATION frames and some DATA frames will not be easy. By this design, ```MetaHeadersFrame``` contains all the method call information except method call parameter. It's time to process the method call request. 

while ```DataFrame``` is a little bit complex. let's make it clear:
* ```HandleStreams()``` run in its goroutine.
* ```HandleStreams()``` does read the data frame which contains the method call parameter. 
* ```handle func(*Stream)``` is a wrapper for ```s.handleStream()```
* ```s.handleStream()``` run in its goroutine.
* ```s.handleStream()``` will block on a channel to wait for the method call parameter.
* in ```HandleStreams()``` goroutine, After ```ReadFrame()``` read the data frame, ```t.handleData()```sends the data frame payload to ```s.handleStream()``` goroutine through the blocked go channel. 
* now ```s.handleStream()``` get the method call parameter, continue the process.

How the two goroutine communicate with each other deserves another chapter. Please see [Request parameter](parameters.md) for detail.

In the following code snippet, the error processing part is folded to avoid distraction.

```go
// HandleStreams receives incoming streams using the given handler. This is
// typically run in a separate goroutine.
// traceCtx attaches trace to ctx and returns the new context.
func (t *http2Server) HandleStreams(handle func(*Stream), traceCtx func(context.Context, string) context.Context) {
    defer close(t.readerDone)
    for {
        t.controlBuf.throttle()
        frame, err := t.framer.fr.ReadFrame()
        atomic.StoreInt64(&t.lastRead, time.Now().UnixNano())
        if err != nil {                               
+-- 26 lines: if se, ok := err.(http2.StreamError); ok {············································································································
            t.Close()                  
            return                                                                                               
        }                  
        switch frame := frame.(type) {                      
        case *http2.MetaHeadersFrame:            
            if t.operateHeaders(frame, handle, traceCtx) {
                t.Close()                                 
                break                                     
            }                                                                                        
        case *http2.DataFrame:                      
            t.handleData(frame)               
        case *http2.RSTStreamFrame:       
            t.handleRSTStream(frame)        
        case *http2.SettingsFrame:          
            t.handleSettings(frame)  
        case *http2.PingFrame:                            
            t.handlePing(frame) case *http2.WindowUpdateFrame:                      t.handleWindowUpdate(frame)                     case *http2.GoAwayFrame:
            // TODO: Handle GoAway from the client appropriately.
        default:                   
            if logger.V(logLevel) {                                                                  
                logger.Errorf("transport: http2Server.HandleStreams found unhandled frame type %v.", frame)
            }                      
        } 
    } 
} 

// ReadFrame reads a single frame. The returned Frame is only valid
// until the next call to ReadFrame.
//
// If the frame is larger than previously set with SetMaxReadFrameSize, the
// returned error is ErrFrameTooLarge. Other errors may be of type
// ConnectionError, StreamError, or anything else from the underlying
// reader.
func (fr *Framer) ReadFrame() (Frame, error) {
    fr.errDetail = nil
    if fr.lastFrame != nil {
        fr.lastFrame.invalidate()
    }
    fh, err := readFrameHeader(fr.headerBuf[:], fr.r)
    if err != nil {    
        return nil, err
    }
    if fh.Length > fr.maxReadSize {
        return nil, ErrFrameTooLarge
    }                           
    payload := fr.getReadBuf(fh.Length)              
    if _, err := io.ReadFull(fr.r, payload); err != nil {
        return nil, err
    }
    f, err := typeFrameParser(fh.Type)(fr.frameCache, fh, payload)
    if err != nil {                         
        if ce, ok := err.(connError); ok {
            return nil, fr.connError(ce.Code, ce.Reason)
        }                                                
        return nil, err
    }                                                        
    if err := fr.checkFrameOrder(f); err != nil {                 
        return nil, err
    }                                     
    if fr.logReads {                                    
        fr.debugReadLoggerf("http2: Framer %p: read %v", fr, summarizeFrame(f))
    }
    if fh.Type == FrameHeaders && fr.ReadMetaHeaders != nil {
        return fr.readMetaFrame(f.(*HeadersFrame))                            
    }                        
    return f, nil
}      
```
```operateHeaders()``` create the stream from the ```MetaHeadersFrame```. Then it check the stream to make sure it's validity. The most important step is to call ```handle(s)``` which is the wrapper function for ```s.handleStream()```. ```s.handleStream()``` is the key to handle gRPC method call request.

Before dive into ```s.handleStream()```, Let's see how the wrapper function works. It check the ```s.opts.numServerWorkers``` to judge whether there is server workers configuration. If the answer is yes, The wrapper will try to send the ```serverWorkerData``` through ```s.serverWorkerChannels[?]``` to one of the server worker. The wrapper use rund robin policy to pick up the server worker. 

If there is no server worker configuration or the choosed server worker is busy, the wrapper start a new goroutine and call ```s.handleStream()```.

In the following code snippet, some part is hided to avoid distraction.
```go
func(stream *transport.Stream) {                                                                                              
    wg.Add(1)                                                                                                          
    if s.opts.numServerWorkers > 0 {                                                                                   
        data := &serverWorkerData{st: st, wg: &wg, stream: stream}                                                     
        select {                                                                                                       
        case s.serverWorkerChannels[atomic.AddUint32(&roundRobinCounter, 1)%s.opts.numServerWorkers] <- data:          
        default:                                                                                                       
            // If all stream workers are busy, fallback to the default code path.                                      
            go func() {                                                                                                
                s.handleStream(st, stream, s.traceInfo(st, stream))                                                    
                wg.Done()                                                                                                                        
            }()                                                                                                        
        }                                                                                                              
    } else {                                                                                                                                       
        go func() {                                                                                                    
            defer wg.Done()                                                                                                         
            s.handleStream(st, stream, s.traceInfo(st, stream))                                                                               
        }()                                                                                                                                                  
    }
}

// operateHeader takes action on the decoded headers.                                                                                                
func (t *http2Server) operateHeaders(frame *http2.MetaHeadersFrame, handle func(*Stream), traceCtx func(context.Context, string) context.Context) (fatal bool) {
    streamID := frame.Header().StreamID
    state := &decodeState{                                                                                                                               
        serverSide: true,                                                                                                                                   
    }
    if h2code, err := state.decodeHeader(frame); err != nil {                                                                                                    
        if _, ok := status.FromError(err); ok {                                                                                                                 
            t.controlBuf.put(&cleanupStream{                                                                                                                   
                streamID: streamID,
                rst:      true,
                rstCode:  h2code,
                onWrite:  func() {},                                                                                                                             
            })
        }
        return false
    }
    
    buf := newRecvBuffer()                                                                                                                                
    s := &Stream{
        id:             streamID,                                                                                                                             
        st:             t,                                                                                                                                    
        buf:            buf,
        fc:             &inFlow{limit: uint32(t.initialWindowSize)},
        recvCompress:   state.data.encoding,
        method:         state.data.method,                                                                                                  
        contentSubtype: state.data.contentSubtype,
    }
    ...
    if frame.StreamEnded() {                                                                                                                          
        // s is just created by the caller. No lock needed.                                                                                                
        s.state = streamReadDone                                                                                                                                 
    }
    if streamID%2 != 1 || streamID <= t.maxStreamID {
        t.mu.Unlock()
        // illegal gRPC stream id.
        if logger.V(logLevel) {
            logger.Errorf("transport: http2Server.HandleStreams received an illegal stream id: %v", streamID)
        }
        s.cancel()
        return true
    }
    ...
    // Register the stream with loopy.
    t.controlBuf.put(&registerStream{
        streamID: s.id,
        wq:       s.wq,
    })
    handle(s)
    return false
}
```
Let's spend some time to understand the server worker mechanism. 

```s.opts.numServerWorkers``` can be set by ```NumStreamWorkers()```. If ```s.opts.numServerWorkers``` is set, ```s.initServerWorkers()``` will be called during ```NewServer``` process. Inside ```s.initServerWorkers()```, several ```s.serverWorker()``` goroutine will be started. ```s.serverWorkerChannels[i]``` is the communication channel. 

```s.serverWorker()``` goroutine blocks on the ```ch chan *serverWorkerData``` channel and wait for the data to be fed by ```serveStreams```. When the for loop runs ```threshold``` times, it will reset the ```s.serverWorker()``` goroutine. The purpose is to reset its stack so that large stacks don't live in memory forever. 

Either invoke ```s.handleStream()``` directly or invoke ```s.handleStream()``` indirectly through ```s.serverWorker()```, ```s.handleStream()``` is the key to handle the gRPC method call request. Remember that ```s.handleStream()``` always runs in its goroutine whaterver direct or indirect invocation.

```go
func NewServer(opt ...ServerOption) *Server {  
    opts := defaultServerOptions                                                                                           
    for _, o := range opt {                                                                                                
        o.apply(&opts)                                                                                                                             
    }                                                                                                                      
    s := &Server{                                                                                                          
        lis:      make(map[net.Listener]bool),                                                                                             
        opts:     opts,                                                                                                    
        conns:    make(map[transport.ServerTransport]bool),                                                                 
        services: make(map[string]*serviceInfo),                                                                                                  
        quit:     grpcsync.NewEvent(),                                                                                                  
        done:     grpcsync.NewEvent(),                                                                                                                   
        czData:   new(channelzData),                                                                                                                  
    }                                                                                                                                                 
    ...
    if s.opts.numServerWorkers > 0 {                                                                                       
        s.initServerWorkers()                                                                                              
    }                                                                                                                                      
                                                                                                                           
    if channelz.IsOn() {                                                                                                    
        s.channelzID = channelz.RegisterServer(&channelzServer{s}, "")                                                                            
    }                                                                                                                                   
    return s                                                                                                                                             
}

// NumStreamWorkers returns a ServerOption that sets the number of worker
// goroutines that should be used to process incoming streams. Setting this to
// zero (default) will disable workers and spawn a new goroutine for each
// stream.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func NumStreamWorkers(numServerWorkers uint32) ServerOption {
    // TODO: If/when this API gets stabilized (i.e. stream workers become the
    // only way streams are processed), change the behavior of the zero value to
    // a sane default. Preliminary experiments suggest that a value equal to the
    // number of CPUs available is most performant; requires thorough testing.
    return newFuncServerOption(func(o *serverOptions) {
        o.numServerWorkers = numServerWorkers
    })
}
...
// serverWorkers blocks on a *transport.Stream channel forever and waits for
// data to be fed by serveStreams. This allows different requests to be
// processed by the same goroutine, removing the need for expensive stack
// re-allocations (see the runtime.morestack problem [1]).
//
// [1] https://github.com/golang/go/issues/18138
func (s *Server) serverWorker(ch chan *serverWorkerData) {
    // To make sure all server workers don't reset at the same time, choose a
    // random number of iterations before resetting.
    threshold := serverWorkerResetThreshold + grpcrand.Intn(serverWorkerResetThreshold)
    for completed := 0; completed < threshold; completed++ {
        data, ok := <-ch
        if !ok {
            return
        }
        s.handleStream(data.st, data.stream, s.traceInfo(data.st, data.stream))
        data.wg.Done()
    }
    go s.serverWorker(ch)
}

// initServerWorkers creates worker goroutines and channels to process incoming
// connections to reduce the time spent overall on runtime.morestack.
func (s *Server) initServerWorkers() {
    s.serverWorkerChannels = make([]chan *serverWorkerData, s.opts.numServerWorkers)
    for i := uint32(0); i < s.opts.numServerWorkers; i++ {
        s.serverWorkerChannels[i] = make(chan *serverWorkerData)
        go s.serverWorker(s.serverWorkerChannels[i])
    }
}
...
type Server struct {                                                          
    opts serverOptions                                                         
                                                                             
    mu       sync.Mutex // guards following                            
    lis      map[net.Listener]bool                          
    conns    map[transport.ServerTransport]bool
    serve    bool
    drain    bool                                                           
    cv       *sync.Cond              // signaled when connections close for GracefulStop
    services map[string]*serviceInfo // service name -> service info     
    events   trace.EventLog                               
  
    quit               *grpcsync.Event          
    done               *grpcsync.Event                    
    channelzRemoveOnce sync.Once                                             
    serveWG            sync.WaitGroup // counts active Serve goroutines for GracefulStop
                                                                                       
    channelzID int64 // channelz unique identification number
    czData     *channelzData
                
    serverWorkerChannels []chan *serverWorkerData
}        
...
type serverWorkerData struct {
    st     transport.ServerTransport
    wg     *sync.WaitGroup
    stream *transport.Stream
}
```
### Handle request
When ```operateHeaders()``` create the stream from the MetaHeadersFrame. One important step is to decode reqeust header from header frame. 

Here is the request header example:
```
:method = POST 
:scheme = http 
:path = /helloworld.Greeter/SayHello 
:authority = localhost
te = trailers 
grpc-timeout = 1S 
content-type = application/grpc+proto
grpc-encoding = gzip 
authorization = Bearer xxxxxx 
```
In the header frame, it's the ```:path``` field contains the service name and method name:
```go 
stream.method = "/helloworld.Greeter/SayHello"
``` 
plase see [Send request headers](request.md#send-request-headers). 

```handleStream()``` splits ```stream.Method() ``` into ```servce``` and ```method```. Then it try to find the registered ```methodHandler``` with the specified ```service="helloworld.Greeter"``` and ```method="SayHello"```. If success, it will find the ```_Greeter_SayHello_Handler```, please refer to [Register service](#register-service) for detail.  ```handleStream()``` also provide a solution for unknown service and/or unknown method. 

for our case, ```s.processUnaryRPC()``` will be called next.
```go
func (s *Server) handleStream(t transport.ServerTransport, stream *transport.Stream, trInfo *traceInfo) {
    sm := stream.Method()
    if sm != "" && sm[0] == '/' {
        sm = sm[1:]
    }
    pos := strings.LastIndex(sm, "/")
    if pos == -1 {
        if trInfo != nil {
            trInfo.tr.LazyLog(&fmtStringer{"Malformed method name %q", []interface{}{sm}}, true)
            trInfo.tr.SetError()
        }
        errDesc := fmt.Sprintf("malformed method name: %q", stream.Method())
        if err := t.WriteStatus(stream, status.New(codes.ResourceExhausted, errDesc)); err != nil {
            if trInfo != nil {
                trInfo.tr.LazyLog(&fmtStringer{"%v", []interface{}{err}}, true)
                trInfo.tr.SetError()
            }
            channelz.Warningf(logger, s.channelzID, "grpc: Server.handleStream failed to write status: %v", err)
        }
        if trInfo != nil {
            trInfo.tr.Finish()
        }
        return
    }
    service := sm[:pos]
    method := sm[pos+1:]

    srv, knownService := s.services[service]
    if knownService {
        if md, ok := srv.methods[method]; ok {
            s.processUnaryRPC(t, stream, srv, md, trInfo)
            return
        }
        if sd, ok := srv.streams[method]; ok {
            s.processStreamingRPC(t, stream, srv, sd, trInfo)
            return
        }
    }
    // Unknown service, or known server unknown method.           
    if unknownDesc := s.opts.unknownStreamDesc; unknownDesc != nil {
        s.processStreamingRPC(t, stream, nil, unknownDesc, trInfo)
        return        
    }                 
    var errDesc string                                      
    if !knownService {
        errDesc = fmt.Sprintf("unknown service %v", service)                      
    } else {
        errDesc = fmt.Sprintf("unknown method %v for service %v", method, service)
    }                                      
    if trInfo != nil {      
        trInfo.tr.LazyPrintf("%s", errDesc)
        trInfo.tr.SetError()                                                               
    }                     
    if err := t.WriteStatus(stream, status.New(codes.Unimplemented, errDesc)); err != nil {
        if trInfo != nil {      
            trInfo.tr.LazyLog(&fmtStringer{"%v", []interface{}{err}}, true)
            trInfo.tr.SetError()                                                                            
        }
        channelz.Warningf(logger, s.channelzID, "grpc: Server.handleStream failed to write status: %v", err)
    }                     
    if trInfo != nil {
        trInfo.tr.Finish()
    }
}
```
```processUnaryRPC()``` perform the following work:
* prepare the compression and decompression object.
* call ```recvAndDecompress()``` to get the gRPC method call parameter data: ```d```.
* prepare the decode function ```df``` for method handler.
* call ```md.Handler()``` to process the gRPC method call, the response is ```reply```
* call ```s.sendResponse()``` to send the response to client. Here the ***Response-Headers*** and ***Length-Prefixed-Message*** will be sent.
* call ``t.WriteStatus()``` to send the trailer to end the stream. Here the ***Trailers*** will be sent.

Now we know the whole picture, let's dive each part one by one.

In the following code snippet, some code is folded to avoid distraction.
```go
func (s *Server) processUnaryRPC(t transport.ServerTransport, stream *transport.Stream, info *serviceInfo, md *MethodDesc, trInfo *traceInfo) (err error) {
+-- 80 lines: sh := s.opts.statsHandler·····························································································································
    // comp and cp are used for compression.  decomp and dc are used for
    // decompression.  If comp and decomp are both set, they are the same;
    // however they are kept separate to ensure that at most one of the
    // compressor/decompressor variable pairs are set for use later.
    var comp, decomp encoding.Compressor
    var cp Compressor 
    var dc Decompressor            
                                      
+-- 27 lines: If dc is set and matches the stream's compression, use it.  Otherwise, try············································································
             
    var payInfo *payloadInfo                          
    if sh != nil || binlog != nil {
        payInfo = &payloadInfo{}
    }                                                  
    d, err := recvAndDecompress(&parser{r: stream}, stream, dc, s.opts.maxReceiveMessageSize, payInfo, decomp)
    if err != nil {                                                               
        if e := t.WriteStatus(stream, status.Convert(err)); e != nil {             
            channelz.Warningf(logger, s.channelzID, "grpc: Server.processUnaryRPC failed to write status %v", e)
        }                                    
        return err
    }                                                                              
    if channelz.IsOn() {                                                         
        t.IncrMsgRecv()                                                            
    }                                                                           
    df := func(v interface{}) error {                   
        if err := s.getCodec(stream.ContentSubtype()).Unmarshal(d, v); err != nil {
            return status.Errorf(codes.Internal, "grpc: error unmarshalling request: %v", err)
        }                                       
        if sh != nil {                                                             
            sh.HandleRPC(stream.Context(), &stats.InPayload{
                RecvTime:   time.Now(),
                Payload:    v,    
                WireLength: payInfo.wireLength + headerLen,
                Data:       d,
                Length:     len(d),
            })
        }
        if binlog != nil {
            binlog.Log(&binarylog.ClientMessage{
                Message: d,
            })
        }
        if trInfo != nil {
            trInfo.tr.LazyLog(&payload{sent: false, msg: v}, true)
        }
        return nil
    }
    ctx := NewContextWithServerTransportStream(stream.Context(), stream)
    reply, appErr := md.Handler(info.serviceImpl, ctx, df, s.opts.unaryInt)
    if appErr != nil {
+-- 27 lines: appStatus, ok := status.FromError(appErr)·············································································································
    }
    if trInfo != nil {
        trInfo.tr.LazyLog(stringer("OK"), false)
    }
    opts := &transport.Options{Last: true}

    if err := s.sendResponse(t, stream, reply, cp, opts, comp); err != nil {
+-- 27 lines: if err == io.EOF {····································································································································
    }
+-- 15 lines: if binlog != nil {····································································································································
    // TODO: Should we be logging if writing status failed here, like above?
    // Should the logging be in WriteStatus?  Should we ignore the WriteStatus
    // error or allow the stats handler to see it?
    err = t.WriteStatus(stream, statusOK)
    if binlog != nil {
        binlog.Log(&binarylog.ServerTrailer{
            Trailer: stream.Trailer(),
            Err:     appErr,
        })
    }
    return err
}
...
type methodHandler func(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor UnaryServerInterceptor) (interface{}, error)
                                                            
// MethodDesc represents an RPC service's method specification.                      
type MethodDesc struct {                                                            
    MethodName string                                                              
    Handler    methodHandler                                  
}

```
```recvAndDecompress()``` call ```p.recvMsg()``` to read the data frame. It's more complex than you can expect. For now, let's assume ```p.recvMsg()``` get the payload of gRPC reqeust. See [Request parameter](parameters.md) for detail. After ```p.recvMsg()``` return, ***Length-Prefixed-Message*** (gRPC request) has been read.

Then check the payload to find some kind of compression error. if the payload is no error and compressed, decompress the payload according to the [gRPC over HTTP2](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md)

```df``` is the decode function used by the ```md.Handler()```. It first get the codec which is protobuf by default. Then it unmarshall the payload to build the gRPC request object. Please check the [Protobuf Official Encoding document](https://developers.google.com/protocol-buffers/docs/encoding).

```md.Handler()``` is the *KEY* to call the gRPC service method. Now the method call request object is ready, it's time to call the ```methodHandler```. Please note it use the ```s.opts.unaryInt``` as the interceptor. See [Interceptor](interceptor.md) for more detail.  You can also refer to [Register service](#register-service) to check how to use ```df``` and ```interceptor``` in a real method handler.

```
The repeated sequence of Length-Prefixed-Message items is delivered in DATA frames
* Length-Prefixed-Message → Compressed-Flag Message-Length Message
* Compressed-Flag → 0 / 1 # encoded as 1 byte unsigned integer
* Message-Length → {length of Message} # encoded as 4 byte unsigned integer (big endian)
* Message → *{binary octet}
```
Finally return the decompressed payload byte slice.

```go
func recvAndDecompress(p *parser, s *transport.Stream, dc Decompressor, maxReceiveMessageSize int, payInfo *payloadInfo, compressor encoding.Compressor) ([]byte, er  ror) {                                                                                                                                       
    pf, d, err := p.recvMsg(maxReceiveMessageSize)  
    if err != nil {                                                                                                                               
        return nil, err
    }                                                                          
    if payInfo != nil {              
        payInfo.wireLength = len(d)                               
    }                                                              
                                                                 
    if st := checkRecvPayload(pf, s.RecvCompress(), compressor != nil || dc != nil); st != nil {
        return nil, st.Err()                              
    }                                 
        
    var size int       
    if pf == compressionMade {        
        // To match legacy behavior, if the decompressor is set by WithDecompressor or RPCDecompressor,
        // use this decompressor as the default.                                                                                                  
        if dc != nil {                                                   
            d, err = dc.Do(bytes.NewReader(d))                                 
            size = len(d)                                  
        } else {                                                        
            d, size, err = decompress(compressor, d, maxReceiveMessageSize)
        }
        if err != nil {
            return nil, status.Errorf(codes.Internal, "grpc: failed to decompress the received message %v", err)
        }
    } else {
        size = len(d)
    }
    if size > maxReceiveMessageSize {
        // TODO: Revisit the error code. Currently keep it consistent with java
        // implementation.
        return nil, status.Errorf(codes.ResourceExhausted, "grpc: received message larger than max (%d vs. %d)", size, maxReceiveMessageSize)
    }
    return d, nil
}
```
```sendResponse()``` send the response to client. It first get the codec and encode (default protobuf) the response to byte slice, then it may compress the response payload and build the payload header. 

Finally call ```t.Write()``` to  write the ***Response-Headers*** and ***Length-Prefixed-Message*** to client. Both ```writeHeaderLocked()``` and ```Write()``` use ```t.controlBuf``` to write back to client. See [controlBuffer and loopy](control.md) for detail.

Here is the response example:
```
HEADERS (flags = END_HEADERS)
:status = 200
grpc-encoding = gzip
content-type = application/grpc+proto

DATA
<Length-Prefixed Message>

HEADERS (flags = END_STREAM, END_HEADERS)
grpc-status = 0 # OK
trace-proto-bin = jher831yy13JHy3hc
```

```go
func (s *Server) sendResponse(t transport.ServerTransport, stream *transport.Stream, msg interface{}, cp Compressor, opts *transport.Options, comp encoding.Compress  or) error {                                                       
    data, err := encode(s.getCodec(stream.ContentSubtype()), msg)
    if err != nil {
        channelz.Error(logger, s.channelzID, "grpc: server failed to encode response: ", err)
        return err                                                      
    }                                                                      
    compData, err := compress(data, cp, comp)
    if err != nil {
        channelz.Error(logger, s.channelzID, "grpc: server failed to compress response: ", err)
        return err    
    }                                           
    hdr, payload := msgHeader(data, compData)
    // TODO(dfawley): should we be checking len(data) instead?
    if len(payload) > s.opts.maxSendMessageSize {
        return status.Errorf(codes.ResourceExhausted, "grpc: trying to send message larger than max (%d vs. %d)", len(payload), s.opts.maxSendMessageSize)
    }
    err = t.Write(stream, hdr, payload, opts)
    if err == nil && s.opts.statsHandler != nil {
        s.opts.statsHandler.HandleRPC(stream.Context(), outPayload(false, msg, data, payload, time.Now()))
    }                                                                         
    return err                                    
}

...
// Write converts the data into HTTP2 data frame and sends it out. Non-nil error
// is returns if it fails (e.g., framing error, transport error).
func (t *http2Server) Write(s *Stream, hdr []byte, data []byte, opts *Options) error {
    if !s.isHeaderSent() { // Headers haven't been written yet.
        if err := t.WriteHeader(s, nil); err != nil {
            if _, ok := err.(ConnectionError); ok {
                return err
            }                                            
            // TODO(mmukhi, dfawley): Make sure this is the right code to return.
            return status.Errorf(codes.Internal, "transport: %v", err)
        }                                                              
    } else {                                                                      
        // Writing headers checks for this condition.              
        if s.getState() == streamDone {
            // TODO(mmukhi, dfawley): Should the server write also return io.EOF?   
            s.cancel()                                                          
            select {                                                           
            case <-t.done:                                                                                 
                return ErrConnClosing                                          
            default:                                                                                             
            }                                                                            
            return ContextErr(s.ctx.Err())                                                                                     
        }        
    }                                                                                                                            
    df := &dataFrame{                                                               
        streamID:    s.id,
        h:           hdr,
        d:           data,
        onEachWrite: t.setResetPingStrikes,
    }
    if err := s.wq.get(int32(len(hdr) + len(data))); err != nil {
        select {
        case <-t.done:
            return ErrConnClosing
        default:
        }
        return ContextErr(s.ctx.Err())
    }
    return t.controlBuf.put(df)
}

...
// WriteHeader sends the header metadata md back to the client.                                                  
func (t *http2Server) WriteHeader(s *Stream, md metadata.MD) error {                     
    if s.updateHeaderSent() || s.getState() == streamDone {                                                                    
        return ErrIllegalHeaderWrite
    }                                                                                                                            
    s.hdrMu.Lock()                                                                  
    if md.Len() > 0 {     
        if s.header.Len() > 0 {
            s.header = metadata.Join(s.header, md)
        } else {                           
            s.header = md
        }                                                        
    }           
    if err := t.writeHeaderLocked(s); err != nil {
        s.hdrMu.Unlock()         
        return err
    }    
    s.hdrMu.Unlock()                  
    return nil
}          

func (t *http2Server) writeHeaderLocked(s *Stream) error {
    // TODO(mmukhi): Benchmark if the performance gets better if count the metadata and other header fields
    // first and create a slice of that exact size.
    headerFields := make([]hpack.HeaderField, 0, 2) // at least :status, content-type will be there if none else.
    headerFields = append(headerFields, hpack.HeaderField{Name: ":status", Value: "200"})
    headerFields = append(headerFields, hpack.HeaderField{Name: "content-type", Value: grpcutil.ContentType(s.contentSubtype)})
    if s.sendCompress != "" {
        headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-encoding", Value: s.sendCompress})
    }
    headerFields = appendHeaderFieldsFromMD(headerFields, s.header)
    success, err := t.controlBuf.executeAndPut(t.checkForHeaderListSize, &headerFrame{
        streamID:  s.id,
        hf:        headerFields,
        endStream: false,
        onWrite:   t.setResetPingStrikes,
    })
    if !success {
        if err != nil {
            return err
        }
        t.closeStream(s, true, http2.ErrCodeInternal, false)
        return ErrHeaderListSizeLimitViolation
    }
    if t.stats != nil {
        // Note: Headers are compressed with hpack after this call returns.
        // No WireLength field is set here.
        outHeader := &stats.OutHeader{
            Header:      s.header.Copy(),
            Compression: s.sendCompress,
        }
        t.stats.HandleRPC(s.Context(), outHeader)
    }
    return nil
}
```
``t.WriteStatus()``` is the last one to be called in ```processUnaryRPC()```. It job is sending stream status to the client and terminates the stream.


```t.Write()``` build the header fields and trailer header frame and send it back with ```t.controlBuf```. Then call ```t.finishStream()``` to end the stream. ```t.finishStream()``` also use ```t.controlBuf``` to write back to client. See [controlBuffer and loopy](control.md) for detail.

Now the ***Trailers*** is sent.
```go
// WriteStatus sends stream status to the client and terminates the stream.
// There is no further I/O operations being able to perform on this stream.
// TODO(zhaoq): Now it indicates the end of entire stream. Revisit if early
// OK is adopted.
func (t *http2Server) WriteStatus(s *Stream, st *status.Status) error {
    if s.getState() == streamDone {
        return nil
    }
    s.hdrMu.Lock()
    // TODO(mmukhi): Benchmark if the performance gets better if count the metadata and other header fields
    // first and create a slice of that exact size.
    headerFields := make([]hpack.HeaderField, 0, 2) // grpc-status and grpc-message will be there if none else.
    if !s.updateHeaderSent() {                      // No headers have been sent.
        if len(s.header) > 0 { // Send a separate header frame.
            if err := t.writeHeaderLocked(s); err != nil {
                s.hdrMu.Unlock()
                return err
            }
        } else { // Send a trailer only response.
            headerFields = append(headerFields, hpack.HeaderField{Name: ":status", Value: "200"})                                      
            headerFields = append(headerFields, hpack.HeaderField{Name: "content-type", Value: grpcutil.ContentType(s.contentSubtype)})
        }
    }
    headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-status", Value: strconv.Itoa(int(st.Code()))})    
    headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-message", Value: encodeGrpcMessage(st.Message())})

    if p := st.Proto(); p != nil && len(p.Details) > 0 {
        stBytes, err := proto.Marshal(p)                                      
        if err != nil {                                                                    
            // TODO: return error instead, when callers are able to handle it.                                                      
            logger.Errorf("transport: failed to marshal rpc status: %v, error: %v", p, err)
        } else {
            headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-status-details-bin", Value: encodeBinHeader(stBytes)})
        }
    }

    // Attach the trailer metadata.
    headerFields = appendHeaderFieldsFromMD(headerFields, s.trailer)
    trailingHeader := &headerFrame{
        streamID:  s.id,
        hf:        headerFields,
        endStream: true,
        onWrite:   t.setResetPingStrikes,
    }
    s.hdrMu.Unlock()
    success, err := t.controlBuf.execute(t.checkForHeaderListSize, trailingHeader)
    if !success {
        if err != nil {
            return err
        }
        t.closeStream(s, true, http2.ErrCodeInternal, false)
        return ErrHeaderListSizeLimitViolation
    }
    // Send a RST_STREAM after the trailers if the client has not already half-closed.
    rst := s.getState() == streamActive
    t.finishStream(s, rst, http2.ErrCodeNo, trailingHeader, true)
    if t.stats != nil {
        // Note: The trailer fields are compressed with hpack after this call returns.
        // No WireLength field is set here.
        t.stats.HandleRPC(s.Context(), &stats.OutTrailer{
            Trailer: s.trailer.Copy(),
        })
    }
    return nil
}
// finishStream closes the stream and puts the trailing headerFrame into controlbuf.
func (t *http2Server) finishStream(s *Stream, rst bool, rstCode http2.ErrCode, hdr *headerFrame, eosReceived bool) {
    oldState := s.swapState(streamDone)                                               
    if oldState == streamDone {        
        // If the stream was already done, return.               
        return         
    }                                                                                 
                                           
    hdr.cleanup = &cleanupStream{                        
        streamID: s.id,               
        rst:      rst,
        rstCode:  rstCode,
        onWrite: func() {
            t.deleteStream(s, eosReceived)
        },
    }                                                                           
    t.controlBuf.put(hdr)                                        
}                                                                                     

```
